{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(125)\n\nfrom keras.models import load_model\nfrom sklearn.externals import joblib\n\noutput_folder = './output'\nmodel_filename = 'final_model.hdf5'\n\nkeras_model = load_model(os.path.join(output_folder, model_filename))\nprint(keras_model.summary())\n\nvectorizer_name = 'vectorizer'\nvectorizer = joblib.load(os.path.join(output_folder, vectorizer_name))\nprint('{} loaded!'.format(vectorizer_name))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import onnxmltools\n\ndeployment_folder = 'deploy'\nonnx_export_folder = 'onnx'\n\n# Convert the Keras model to ONNX\nonnx_model_name = 'reviews_classifier.onnx'\nconverted_model = onnxmltools.convert_keras(keras_model, onnx_model_name, target_opset=7)\n\n# Save the model locally...\nonnx_model_path = os.path.join(deployment_folder, onnx_export_folder)\nos.makedirs(onnx_model_path, exist_ok=True)\nonnxmltools.utils.save_model(converted_model, os.path.join(onnx_model_path,onnx_model_name))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import onnxruntime\n# Load the ONNX model and observe the expected input shape\nonnx_session = onnxruntime.InferenceSession(\n    os.path.join(os.path.join(deployment_folder, onnx_export_folder), onnx_model_name))\ninput_name = onnx_session.get_inputs()[0].name\noutput_name = onnx_session.get_outputs()[0].name\nprint('Expected input shape: ', onnx_session.get_inputs()[0].shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk\nnltk.download('stopwords')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import sys\ndata_location = './data'\nsys.path.append(data_location)\nimport textanalytics as ta",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nltk.download('punkt')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_review = ['The room was very nice and the beds were especially comfortable.']\ntest_review = ta.normalize_corpus(test_review)\ntest_review = vectorizer.transform(test_review)\n\ntest_review = test_review.toarray().astype(np.float32)\nprint(test_review.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run an ONNX session to classify the sample.\nprint('ONNX prediction: ', onnx_session.run([output_name], {input_name : test_review}))\n\n# Use Keras to make predictions on the same sample\nprint('Keras prediction: ', keras_model.predict(test_review))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Next we will compare the performance of ONNX vs Keras\nimport timeit\nn = 20000",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = timeit.default_timer()\nfor i in range(n):\n    keras_model.predict(test_review)\nkeras_elapsed = timeit.default_timer() - start_time\nprint('Keras performance: ', keras_elapsed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = timeit.default_timer()\nfor i in range(n):\n    onnx_session.run([output_name], {input_name : test_review})\nonnx_elapsed = timeit.default_timer() - start_time\nprint('ONNX performance: ', onnx_elapsed)\nprint('ONNX is about {} times faster than Keras'.format(round(keras_elapsed/onnx_elapsed)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!cat .azureml/config.json",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\n\nprint(azureml.core.VERSION)\n\nfrom azureml.core.workspace import Workspace\n\nws = Workspace.from_config()\nprint(ws)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Register the model and vectorizer\nfrom azureml.core.model import Model\n\nregistered_model_name = 'reviews_classifier_onnx'\nonnx_model_path = os.path.join(os.path.join(deployment_folder, onnx_export_folder), onnx_model_name)\n\nregistered_model = Model.register(model_path = onnx_model_path, # this points to a local file\n                       model_name = registered_model_name, # this is the name the model is registered with         \n                       description = \"Reviews classification model.\",\n                       workspace = ws)\n\nprint(registered_model.name, registered_model.description, registered_model.version)\n\noutput_folder = './output'\nvectorizer_name = 'vectorizer'\nvectorizer_path = os.path.join(output_folder, vectorizer_name)\n\nregistered_vectorizer = Model.register(model_path = vectorizer_path, # this points to a local file\n                       model_name = vectorizer_name, # this is the name the model is registered with         \n                       description = \"Reviews classification model vectorizer.\",\n                       workspace = ws)\n\nprint(registered_vectorizer.name, registered_vectorizer.description, registered_vectorizer.version)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cwd = os.getcwd()\nif cwd.endswith(deployment_folder):\n    os.chdir('../')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $deployment_folder/scoring_service.py\nimport json\nimport numpy as np\nimport os\nimport sys\nimport urllib.request\nimport nltk\nfrom sklearn.externals import joblib\nfrom azureml.core.model import Model\nimport onnxruntime\n\nonnx_model_name = 'reviews_classifier_onnx'\nvectorizer_name = 'vectorizer'\n\ndef init():\n\n    global onnx_session\n    global vectorizer\n    \n    try:\n        # Takes at most a couple of minutes to download all NLTK content\n        print(\"downloading nltk.\")\n        nltk.download(\"all\")\n        \n        tempFolderName = './resources'\n        os.makedirs(tempFolderName, exist_ok=True)\n        print('Content files will be saved to {0}'.format(tempFolderName))\n        \n        base_data_url = 'https://raw.githubusercontent.com/idiWork/Experiment_102/master/'\n        filesToDownload = ['contractions.py', 'textanalytics.py']\n        \n        for file in filesToDownload:\n            data_url = os.path.join(base_data_url, file)\n            local_file_path = os.path.join(tempFolderName, file)\n            urllib.request.urlretrieve(data_url, local_file_path)\n            print('Downloaded file: ', file)\n        \n        print('Importing textanalytics...')\n        sys.path.append(tempFolderName)\n        import textanalytics as ta\n        print('Done importing textanalytics.')\n        \n        # Retrieve the path to the model file using the model name\n        onnx_model_path = Model.get_model_path(onnx_model_name)\n        print('onnx_model_path: ', onnx_model_path)\n        \n        vectorizer_path = Model.get_model_path(vectorizer_name)\n        print('vectorizer_path: ', vectorizer_path)\n        \n        onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n        print('Onnx Inference Session Created!')\n        \n        vectorizer = joblib.load(vectorizer_path)\n        print('Vectorizer Loaded!')\n    except Exception as e:\n        print(e)\n\ndef run(raw_data):\n    try:\n        print(\"Received input: \", raw_data)\n        \n        print('Importing textanalytics...')\n        import textanalytics as ta\n        print('Done importing textanalytics.')\n        \n        print('Processing input...')\n        input_data = np.array(json.loads(raw_data))\n        input_data = ta.normalize_corpus(input_data)\n        input_data = vectorizer.transform(input_data)\n        input_data = input_data.toarray().astype(np.float32)\n        print('Done processing input.')\n        \n        # Run an ONNX session to classify the input.\n        result = onnx_session.run(None, {onnx_session.get_inputs()[0].name: input_data})[0].argmax(axis=1).item()\n        # return just the classification index (0 or 1)\n        return result\n    except Exception as e:\n        print(e)\n        error = str(e)\n        return error",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create a Conda dependencies environment file\nprint(\"Creating conda dependencies file locally...\")\nfrom azureml.core.conda_dependencies import CondaDependencies \nconda_packages = ['numpy', 'scikit-learn']\npip_packages = ['nltk', 'azureml-sdk', 'onnxruntime']\nmycondaenv = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n\ncwd = os.getcwd()\nif not cwd.endswith(deployment_folder):\n    os.chdir(deployment_folder)\n    \nconda_file = 'dependencies.yml'\nwith open(conda_file, 'w') as f:\n    f.write(mycondaenv.serialize_to_string())\n\nruntime = 'python'\nexecution_script = 'scoring_service.py'\n\n# create container image configuration\nprint(\"Creating container image configuration...\")\nfrom azureml.core.image import ContainerImage\nimage_config = ContainerImage.image_configuration(execution_script = execution_script, \n                                                  runtime = runtime, conda_file = conda_file)\n\n# create the image\nimage_name = 'review-classifier-image'\n\nfrom azureml.core import Image\nimage = Image.create(name=image_name, models=[registered_model, registered_vectorizer], \n                     image_config=image_config, workspace=ws)\n\n# wait for image creation to finish\nimage.wait_for_creation(show_output=True)\n\nos.chdir(\"..\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice, Webservice\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name': 'Review Classification'}, \n    description = \"Classifies a review as room (0), diner (1) or pool (2).\")\n\nservice_name = \"reviewclassservice\"\n\naci_service = Webservice.deploy_from_image(deployment_config=aci_config, \n                                           image=image, \n                                           name=service_name, \n                                           workspace=ws)\n\naci_service.wait_for_deployment(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\n\ntest_reviews = ['The room was very nice and the beds were especially comfortable.', \n               'The kids loved going to the Kids Club at the swimming pool.', \n               'The food was great and the buffet was priced very reasonably.']\n\nfor i in range(len(test_reviews)):\n    result = aci_service.run(json.dumps([test_reviews[i]]))\n    print('Predicted label for test review #{} is {}'.format(i+1, result))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\n\nurl = aci_service.scoring_uri\nprint('ACI Service: Review Classification scoring URI is: {}'.format(url))\nheaders = {'Content-Type':'application/json'}\n\nfor i in range(len(test_reviews)):\n    response = requests.post(url, json.dumps([test_reviews[i]]), headers=headers)\n    print('Predicted label for test review #{} is {}'.format(i+1, response.text))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}